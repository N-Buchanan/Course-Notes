\documentclass{article}

\usepackage{../courseNotes}

\courseName{Numerical Computation}
\courseCode{CS 370}
\prof{George Lahban}
\auth{Nolan Buchanan}
\secName{Topic}
\term{4A}


\begin{document}

\tpage
\lecture{15-09-15}
The course will cover $5$ topics.

\begin{enumerate}
	\item Floating Point Arithmetic
		\begin{itemize}
			\item What is this?
			\item What goes wrong?
			\item How to analyze errors
		\end{itemize}
	\item Interpolation + Splines + Parametric Curves
		\begin{itemize}
			\item Motivation: Graphics
			\item Issues: Move from discrete data to a continuous formula
			\item Application: Handwritten letters, fonts
		\end{itemize}
	\item Initial Value Problems
		\begin{itemize}
			\item $y'(t) = f(t,y(t)), y(t_0) = y_0$
			\item Motivation: Prediction of motion
			\item Application: Predator/prey, Angry Birds
		\end{itemize}
	\item Discrete Fourier Analysis
		\begin{itemize}
			\item Motivation: signal processsing, data compression
			\item Application: iPods, CSI
		\end{itemize}
	\item Numerical Linear Algebra
		\begin{itemize}
			\item Motivation: effectively solve a linear systems equation
			\item Application: Google PageRank
		\end{itemize}
\end{enumerate}

\section{Floating Point Arithmetic}

\begin{itemize}
	\item Computer arithmetic is approximate arithmetic
		\subitem Real numbers require infinite digits
		\subitem Computer numbers have finite digits
		\subitem $\sqrt{2}, \pi, e$ don't exist (typically)
\end{itemize}
Thus, computer arithmetic computations are not always correct.

\textbf{Examples}
\begin{enumerate}
	\item $e^{-5.5}$ usig $5$ digit accuracy.
		Recall the Taylor expansion:
		$e^x = 1 + x + \frac{x^2}{2} + \frac{x^3}{6}  + \dots + \frac{x^n}{n!}$
		Also:
		$e^{-x} = \sum_{i=0}^{\infty} \frac{(-1)^ii}{i!}$

		After $25$ terms, the first $5$ digits stop changing

		By calculating using $e^{-5.5}$ we get $0.0026363$ but calculating using $\frac{1}{e^{5.5}}$ we get $0.0040868$.

	\item $x^2 + 62.1x + 1 = 0$ to an accuracy of $4$ digits.

		$$x_1 = \frac{-b + \sqrt{b^2 - 4ac}}{2a} = -0.0200$$
		$$x_2 = \frac{-b - \sqrt{b^2 - 4ac}}{2a} = -62.1$$

		$a(x-x_1)(x-x_2) = ax^2+bx+c \rightarrow ax_1x_2 = c \rightarrow x_1 = \frac{c}{ax_2}, x_2 = \frac{-b - \sqrt{b^2 - 4ac}}{2a}$

		This yields $x_1 = -0.0161$ and $x_2$ remains $-62.1$. Obviously not the same.

	\item $\int_0^1 \frac{x^n}{x+ \alpha} dx = I_n$ Assume $\alpha$ is given and we want to find $I_0, I_1, I_2, I_100$

		$I_0 = \int_0^1 \frac{x^n}{x+ \alpha} dx  = \int_0^1 \frac{(x + \alpha - \alpha) x^{n-1}}{x+\alpha}dx = \int_0^1 \frac{(x + \alpha)x^{n-1}}{x + \alpha}dx - \alpha \int_0^1 \frac{x^{n-1}}{x + \alpha}dx$

		$= \int_0^1 x^{n-1} dx - \alpha \int_0^1 \frac{x^{n-1}}{x + \alpha}dx = \frac{x^n}n |_0^1 - \alpha \int_0^1 \frac{x^{n-1}}{x + \alpha}dx $ % not sure about the pipe
		$ = \frac{1}n - \alpha I_{n-1}$

		Programming this gives us:
		$\alpha = 0.5 \rightarrow I_{100} = 0.00646, \alpha = 2.0 \rightarrow I_{100} = 2.1 \times 10^{27}$

		If $\alpha$ is greater than $0$, then $\frac{x^n}{x + \alpha}$ cannot be greater than $1$ within the bounds of the integal. Thus, $\times 10^{27}$ is impossible.

\end{enumerate}

\lecture{17-09-15}
Real numbers look like $0$ or $0.\beta_1, \beta_2, \dots , \beta_t, \dots \times \beta^p$ with $\beta_1 \neq 0, 0 \leq \beta_i < \beta$ where $\beta$ is the base.

Floating poing number system: $F(\beta, t, L, u)$ (base, precision, lowwer bound, upper bound) with numbers $0$ or $0.\beta_1 \beta_2 \dots \beta_t \times \beta^p$ and $\beta_1 \neq 0, 0 \leq \beta_i < \beta, L \leq p \leq u$.

For example, in base $10$ with six digits $\pi = 0.314159 \times 10^1$

Single Precision is represented as $F(2, 24, -126, 127)$. In other words:\\
$1$ bit for $\pm$\\
$8$ bits for the exponent\\
$23$ bits for the number

Double precision is represented as $F(2, 53, -1022, 1023)$. In other words:\\
$1$ bit for $\pm$\\
$11$ bits for the exponent\\
$52$ bits for the number

Note: 
\begin{equation*}
	x &= \text{real number}
	&= \plusminus 0.x_1x_2 \dots x_t \dots \times \beta^p
	fl(x) &=\plusminus 0.x_1x_2 \dots x_t \times \beta^p
\end{equation*}

Error?
There is a relative error of $\frac{fl(x) - x}{x} = \delta$

Note that $\delta x = fl(x) - x \rightarrow fl(x) = x(1+\delta)$

We can bound any relative error:
\begin{equation*}
	|\delta| &= \left| \frac{0.00 \dots x_{x+1} x_{1+2} \dots \times \beta^p}{0.x_1x_2 \dots x_{x+1} x_{1+2} \dots \times \beta^p} \right|
	& = \left| \frac{0.x_{x+1} x_{1+2} \dots \times \beta^{-t}}{x_1.x_2 \dots x_{x+1} x_{1+2} \dots \times \beta^{-1}} \right|
	&= \left| \frac{0.x_{x+1} x_{1+2} \dots }{x_1.x_2 \dots x_{x+1} x_{1+2} \dots } \right| \beta^{1-t} < \beta^{1-t} (truncation)
	&= \left| \frac{0.x_{x+1} x_{1+2} \dots }{x_1.x_2 \dots x_{x+1} x_{1+2} \dots } \right| \beta^{1-t} < \frac{1}{2}\beta^{1-t} (rounding)
\end{equation*}

To simplify we define machine-epsilon as :

$$\epsilon = \beta^{1-t} (truncation), \frac 12 \beta^{1-t}(rounding)$$ %TODO: need to get piecewise functions working again

$$fl(x) = x(1+ \delta), | \delta | < \epsilon$$

Floating Point arithmetic
If $x$  and $y$ are two real numbers, $x \oplus y = fl(fl(x) + l(y))$

For example, $x = 0.11111111 \dots, y = 0.11101110 \dots$. Using four digit accuracy we have:
\begin{equation*}
	x \oplus y &= 0.1111 + 0.1110
	& = 1.1101
	& = 0.11101 \times 2^1
	& = 0.1110 \times 2^1 \leftarrow \text{truncated}
	& = 1.110
\end{equation*}
Note that this gives a second way to describe machine-epsilon i.e. it is the smallest non-zero number such that $1 \oplus \epsilon > 1$.

Analyzing Floating Point Arithmetic
$x,y$ are real numbers.

\begin{equation*} %TODO: insert equation
	
\end{equation*}

Note: If $x,y$ are of the same sign then $\frac{|x| + |y|}{|x+y|} = 1$ but if $x,y$ are of opposite signs and $x+y$ is approximately $0$ then $\frac{|x| + |y|}{|x+y|}$ can be very large! This is called catastrophic cancellation.
\end{document}
